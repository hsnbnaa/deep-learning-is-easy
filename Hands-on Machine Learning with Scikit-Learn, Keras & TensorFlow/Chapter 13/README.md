# ğŸ“Š Bab 13: Memuat dan Memproses Data dengan TensorFlow  
ğŸ“ File: `13_loading_and_preprocessing_data.ipynb`

---

## ğŸ§­ Ringkasan Bab

Bab ini membahas pentingnya **memuat dan memproses data secara efisien**, terutama untuk **dataset skala besar** yang tidak dapat ditangani sepenuhnya oleh Pandas atau transformer Scikit-Learn. Solusi utama yang diperkenalkan adalah **TensorFlow `tf.data` API**, yang dirancang untuk efisiensi, paralelisme, dan skalabilitas.

---

## âš™ï¸ Mengapa `tf.data`?

- ğŸš… **Efisien dan Paralel**  
  Mendukung pemuatan data secara **multithreaded**, **parallel**, dan **streaming**.

- ğŸ” **Pipelining Otomatis**  
  Saat GPU/TPU melatih batch saat ini, CPU menyiapkan batch berikutnya.

- ğŸ”„ **Optimalisasi Aliran Data**  
  Sering kali **bottleneck bukan di model**, melainkan di tahap pemuatan data.

---

## ğŸ“‚ Format File yang Didukung

- ğŸ“„ **CSV dan file teks**  
- ğŸ“¦ **File biner tetap atau variabel**
- ğŸ§¬ **TFRecord**  
  Format biner efisien untuk skala besar; mendukung Protocol Buffers.

---

## ğŸ§ª Langkah-Langkah Kunci dalam Pipeline Data

1. ğŸ”— **Chaining Transformations**  
   Susun berbagai tahap transformasi (`map`, `filter`, `batch`, dll.) ke dalam satu alur pipeline.

2. ğŸ”€ **Shuffling**  
   Acak data untuk mencegah pembelajaran urutan tidak relevan.

3. ğŸ“ **Interleaving from Multiple Files**  
   Membaca baris dari banyak file secara serentak (efisien dan merata).

4. ğŸ§¹ **Preprocessing Data**  
   Termasuk normalisasi, encoding kategori, penanganan nilai hilang, dan transformasi lainnya.

5. âš¡ **Prefetching**  
   Data batch berikutnya dimuat sambil model melatih batch saat ini â†’ meningkatkan utilisasi GPU.

---

## ğŸ¤– Integrasi dengan `tf.keras`

- Dataset `tf.data` dapat **langsung digunakan** sebagai input ke `.fit()`, `.evaluate()`, dan `.predict()` dalam Keras.
- Dukungan penuh untuk **batching otomatis**, **shuffling**, dan **prefetching**.

---

## ğŸ§  Insight Penting

Mengoptimalkan proses **loading & preprocessing data** sama pentingnya dengan merancang arsitektur model. Untuk pelatihan berskala besar, **efisiensi data pipeline** dapat berdampak langsung pada waktu pelatihan dan penggunaan sumber daya.

---
