# ğŸ“˜ Bab 8: Reduksi Dimensi (Dimensionality Reduction)  
ğŸ“ File: `08_dimensionality_reduction.ipynb`

---

## ğŸ¯ Tujuan Bab

Bab ini membahas salah satu tantangan utama dalam Machine Learning modern:  
**ğŸ”º Curse of Dimensionality** â€” ketika data memiliki terlalu banyak fitur, menyebabkan pelatihan lambat, performa buruk, dan sulitnya menemukan solusi yang baik.

ğŸ”§ Solusi yang ditawarkan adalah **Reduksi Dimensi**:  
â†’ Teknik untuk menyederhanakan representasi data dengan mengurangi jumlah fitur tanpa kehilangan terlalu banyak informasi penting.

---

## âš–ï¸ Trade-off Praktis

> ğŸ­ Reduksi dimensi = seperti kompresi JPEG â†’ Lebih ringan, tapi bisa mengorbankan sedikit kualitas.

- âœ… Keuntungan:
  - Mempercepat pelatihan
  - Mengurangi overfitting
  - Memudahkan visualisasi data
- âŒ Kekurangan:
  - Kehilangan sebagian informasi
  - Menambah kompleksitas pipeline
  - Bisa sedikit menurunkan performa model

ğŸ“Œ Saran: Coba latih model dengan data asli dulu. Gunakan reduksi dimensi **jika** pelatihan terlalu lambat atau data terlalu besar.

---

## ğŸ§­ Dua Pendekatan Utama

### ğŸª 1. Proyeksi
- Memproyeksikan data dari dimensi tinggi â†’ dimensi lebih rendah
- Teknik klasik dan cepat

### ğŸ§© 2. Manifold Learning
- Asumsi: data sebenarnya hidup di "permukaan" (manifold) berdimensi rendah dalam ruang berdimensi tinggi
- Tujuan: temukan manifold tersebut

---

## ğŸ“Œ Algoritma Utama: PCA (Principal Component Analysis)

### ğŸ” Konsep:
- Menemukan **sumbu-sumbu baru (komponen utama)** yang menangkap varian terbesar
- Memungkinkan kita menyimpan **informasi terpenting dengan fitur lebih sedikit**

### âš™ï¸ Fitur PCA:
- ğŸ”¢ **Proyeksi ke d dimensi** â†’ kurangi dimensi asli
- ğŸ“Š **Rasio Varians yang Dijelaskan** â†’ bantu memilih berapa banyak dimensi yang dipertahankan
- ğŸ’¾ **PCA untuk Kompresi** â†’ simpan data dengan ukuran lebih kecil

### ğŸ› ï¸ Implementasi:
- Gunakan `Scikit-Learn` untuk:
  - PCA biasa
  - Randomized PCA (untuk dataset besar)
  - Incremental PCA (untuk data streaming)

---

## ğŸ” Algoritma Tambahan

### ğŸ“Œ Random Projection
- Teknik proyeksi acak yang sangat cepat dan efisien

### ğŸ“Œ LLE (Locally Linear Embedding)
- Metode manifold learning untuk menemukan struktur non-linear lokal

---

## ğŸ’¡ Insight Utama

> ğŸ“‰ **Reduksi Dimensi bukan hanya tentang efisiensi, tapi juga pemahaman struktur data.**  
> ğŸ”€ Pilih teknik berdasarkan tujuan: kecepatan, interpretabilitas, atau akurasi.

> ğŸ”§ Efisiensi model sering kali datang dengan harga: kehilangan presisi.  
> âš–ï¸ Penting untuk memahami trade-off dan menyesuaikan dengan kebutuhan proyek ML.

---
