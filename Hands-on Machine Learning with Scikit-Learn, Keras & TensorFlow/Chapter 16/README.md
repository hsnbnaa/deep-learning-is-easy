# ðŸ§  Bab 16: NLP dengan RNN dan Attention  
ðŸ“ File: `16_nlp_with_rnns_and_attention.ipynb`

---

## ðŸ“œ Ringkasan Bab

Bab ini memperkenalkan **Pemrosesan Bahasa Alami (Natural Language Processing / NLP)** â€” bidang AI yang berfokus pada pemahaman dan generasi bahasa manusia. Topik utama mencakup penggunaan **RNN**, **mekanisme perhatian (attention)**, dan **Transformer**, yang telah merevolusi NLP modern.

---

## ðŸ“š Fokus NLP

- ðŸ—£ï¸ **Tugas-Tugas NLP Umum**:
  - Klasifikasi teks
  - Terjemahan mesin
  - Ringkasan otomatis
  - Penjawaban pertanyaan
  - Pembuatan teks

- ðŸ“– **RNN Karakter**:
  - Model dilatih untuk memprediksi karakter berikutnya dari teks.
  - Dapat digunakan untuk menghasilkan teks baru dari contoh pelatihan.

---

## ðŸ”„ Arsitektur Terjemahan Bahasa

- ðŸ” **Encoderâ€“Decoder RNN**:
  - Encoder memproses input (bahasa sumber).
  - Decoder menghasilkan output (bahasa target).
  - Digunakan untuk tugas terjemahan mesin.

---

## âš¡ Revolusi Transformer

- âš™ï¸ **Transformer Model**:
  - Mengandalkan **self-attention**.
  - Mengatasi keterbatasan RNN pada urutan panjang dan pelatihan lambat.
  - Mendukung paralelisme dan lebih efisien di GPU.

- ðŸ§® **Keunggulan**:
  - Menangani dependensi jangka panjang dengan lebih baik.
  - Lebih mudah ditingkatkan dan dilatih secara efisien.

---

## ðŸ§  Model Bahasa Besar

- ðŸ”€ **Switch Transformers**:
  - Mengaktifkan subset parameter berbeda untuk tiap token input.

- ðŸ”¤ **DistilBERT, T5, dan PaLM**:
  - Model besar yang sukses dalam banyak tugas NLP.

- ðŸ§© **Chain-of-Thought Prompting**:
  - Memungkinkan model menyusun langkah penalaran sebelum jawaban akhir.
  - Meningkatkan kemampuan reasoning dan akurasi.

---

## ðŸ” Transformasi ke Luar NLP

- ðŸ–¼ï¸ **Vision Transformers (ViT)**:
  - Gambar dibagi menjadi patch, lalu diproses seperti token teks.
  - Dapat menangani tugas visi komputer secara efisien.

- ðŸŒ **Model Visual Transformer Lain**:
  - DeiT, Perceiver, DINO

- ðŸŒŸ **Model Multimodal Besar**:
  - CLIP, DALLÂ·E, Flamingo, GATO
  - Mampu memproses kombinasi modalitas: teks, gambar, audio, dll.

---

## ðŸ’¡ Insight Penting

> Arsitektur Transformer dan attention telah mentransformasi NLP dan memperluas kemampuan deep learning ke berbagai domain â€” menandai era **model serbaguna dan multimodal**.

---
